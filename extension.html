<!DOCTYPE html>
<!--[if lt IE 7]><html class="ie ie6" lang="en"> <![endif]-->
<!--[if IE 7]><html class="ie ie7" lang="en"> <![endif]-->
<!--[if IE 8]><html class="ie ie8" lang="en"> <![endif]-->
<!--[if (gte IE 9)|!(IE)]><!-->
<html lang="en">
  <!--<![endif]-->

  <head>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML-full"></script>

    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />

    <meta name="description" content="Haibin Zhao 赵海滨" />
    <meta name="author" content="Haibin Zhao" />

    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1"
    />

    <title>Haibin Zhao</title>

    <!-- STYLES -->
    <link
      href="https://fonts.googleapis.com/css2?family=Mulish:ital,wght@0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap"
      rel="stylesheet"
    />
    <link
      href="https://fonts.googleapis.com/css?family=Montserrat:200i,300,300i,400,400i,500,500i,600,700,700i,800&display=swap"
      rel="stylesheet"
    />
    <link
      href="https://fonts.googleapis.com/css2?family=Poppins:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap"
      rel="stylesheet"
    />

    <link rel="stylesheet" type="text/css" href="css/plugins.css" />
    <link rel="stylesheet" type="text/css" href="css/colors.css" />
    <link rel="stylesheet" type="text/css" href="css/darkMode.css" />
    <link rel="stylesheet" type="text/css" href="css/style.css" />
    <!--[if lt IE 9]>
      <script type="text/javascript" src="js/modernizr.custom.js"></script>
    <![endif]-->
    <!-- /STYLES -->
  </head>

  <body>
    <div class="arlo_tm_news">
        <div class="container">
            <div class="arlo_tm_main_title">
                <h3>Extension of Analog Neuromorphic Circuit</h3>
            </div>
            <div class="list_inner">
                <div class="section-spacing"></div>
                <div class="section-spacing"></div>

                <div class="mytext">
                    Most of the existing works on the design and optimization of
                    neuromorphic circuits are still limited in the computing paradigm of
                    MLPs. This strongly limits the applications of the neuromorphic
                    circuits, because many tasks, such as time-series processing, are
                    beyond the capability of MLPs.
                </div>

                <div class="section-spacing"></div>
                <h4>Recurrent neuromorphic circuit</h4>
                <div class="section-spacing"></div>
                <figure>
                    <img src="img/myfigures/pLF.png" alt="Analog Neuromorphic Circuit" style="width: 70%" />
                    <figcaption>Figure 1: Neuromorphic temporal processing block with learnable filters.</figcaption>
                </figure>
                <div class="mytext">
                    The essential problem of the existing neuromorphic circuits is that
                    they lack the components with time dependencies. I.e., the circuit
                    cannot memorize or store the historical input information. To
                    address this problem, we augmented the neuromorphic circuits with
                    <b>learnable filters</b> (figure 1).
                </div>
                <div class="mytext">
                    The mathematical model of this temporal processing block is
                    expressed by
                    <p>
                        $$ \begin{aligned} V_{k}^{\rm F} &= \beta'\cdot V_{k-1}^{\rm F} +
                        (1-\beta')\cdot {\rm ptanh}(W_1 V_{k}^{\rm in}+b_1)\\ V_{k}^{\rm
                        out} &= {\rm ptanh}(W_2 V_{k}^{\rm F}+b_2) \end{aligned} $$
                    </p>
                </div>
                <div class="mytext">
                    forming an instance of the recurrent neural network (RNN). The
                    proposed circuit is able to efficiently process temporal information
                    and reaches comparable performance to the classic Elman RNN.
                </div>

                <div class="section-spacing"></div>
                <h4>Spiking neuromorphic circuit</h4>
                <div class="section-spacing"></div>
                <div class="mytext">
                    Spiking neural networks are the most biologically plausible neural
                    networks, which allows event-based signal processing, and thus
                    become energy-efficient. Also, the spike-based information delivery
                    is more robust to noise. Therefore, we proposed a spiking
                    neuromorphic circuit (figure 2).
                </div>
                <figure>
                    <img src="img/myfigures/snn.png" alt="Analog Neuromorphic Circuit" style="width: 60%" />
                    <figcaption>Figure 2: Schematic of the spiking neuromorphic circuit.</figcaption>
                </figure>
                <div class="mytext">
                    The proposed circuit can effectively process signals and achieve
                    comparable performance to previous MLP-like neuromorphic circuits
                    with much less energy consumption.
                </div>

                <div class="section-spacing"></div>
                <h4>Related Materials</h4>
                <div class="section-spacing"></div>
                <div class="mytext">
                    <ul>
                        <li>
                            <b>H. Zhao</b> <i>et al</i>. Towards Temporal Information
                            Processing - Printed Neuromorphic Circuit with Learnable
                            Filters. In Proceedings of International Symposium on Nanoscale
                            Architectures (NanoArch), ACM, 2023.
                            <a href="papers/2023 NanoArch -- Towards Temporal Information Processing – Printed Neuromorphic Circuits with Learnable Filters (paper).pdf" download target="_blank"><b>[PDF]</b></a>
                            <!-- <a href="slides/2023 ICCAD -- Power-Aware Training for Energy-Efficient Printed Neuromorphic Circuits (presentation).pdf" download target="_blank"><b>[Slide]</b></a> -->
                            <a href="https://github.com/Neuromophic/LearnableFilters" target="_blank"><b>[Github]</b></a>
                            <!-- <a href="https://www.youtube.com/watch?v=w-LW_8nwX9M&t=6s" target="_blank"><b>[YouTube]</b></a> -->
                        </li>
                        <li>
                            P. Pal, <b>H. Zhao</b> <i>et al</i>. Analog Printed Spiking
                            Neuromorphic Circuits. In Proceedings of Design, Automation &
                            Test in Europe Conference & Exhibition (DATE), IEEE, 2024.
                            <a href="papers/2024_DATE___Analog_Printed_Spiking_Neuromorphic_Circuit.pdf" download target="_blank"><b>[PDF]</b></a>
                            <!-- <a href="slides/2023 DATE -- Split Additive Manufacturing for Printed Neuromorphic Circuits (presentation).pdf" download target="_blank"><b>[Slide]</b></a> -->
                            <a href="https://github.com/Neuromophic/Printed_Spiking_NN" target="_blank"><b>[Github]</b></a>
                            <!-- <a href="https://www.youtube.com/watch?v=Y8KnAOZfLPo&t=539s" target="_blank"><b>[YouTube]</b></a> -->
                        </li>
                        <li>
                            <a href="slides/phdintroduction.pdf" target="_blank"><b>[Introduction of my dissertation]</b></a>
                          </li>
                        <li>
                            Supervised Proseminar of <b>V.  Iliev</b>, Brain-inspired Computation Using Spiking Neural Networks. 2023.
                            <a href="papers/2023_Seminar_Viktor___Spiking_Neural_Networks__Copy_.pdf" download target="_blank"><b>[PDF]</b></a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
    </div>
</body>

</html>
